---
title: "[Debate-Ducks] 체험 토론"
date: 2022-08-19
categories:
  - <Projects>
tags:
  - "'Debate-Ducks'"
  - (Devlog)
---

## 체험 토론 제작

_\*[Pull Request](https://github.com/SuSang-YuHee/Debate-Ducks-Client/pull/116)_

![experience](https://user-images.githubusercontent.com/84524514/185721859-fcba7c84-4c95-422f-a191-ead08ac10b99.gif)

체험 토론을 따로 만들지만 유지 보수성을 위해 기존 토론의 코드를 그대로 사용하고 싶었다. 기존 토론을 만들 때 체험 토론을 고려하고 만들지 않았지만 기존 코드를 80% 이상 재활용하고 스타일은 100% 재활용할 수 있었다.

### 토론 진행 기능

자잘한 수정을 제외하면 크게 두 기능을 새로 만들었다. 우선 socket.io 대신 setInterval을 이용한 토론 진행 기능이다. 처음에는 `handleDebate`를 setInterval에 넣어서 작성했는데 제대로 작동하지 않았다.

```ts
const handleDebate = () => {
    if (curDebate.turn < 7 && curDebate.time < 1) {
      setCurDebate((prevState) => ({
        ...prevState,
        notice: debateProgress[prevState.turn + 1][0],
        turn: prevState.turn + 1,
        time: debateProgress[prevState.turn + 1][1],
      }));
    } else {
      setCurDebate((prevState) => ({
        notice: prevState.notice,
        turn: prevState.turn,
        time: prevState.time - 1,
      }));!
    }
    ...
}
```

setInterval이 시작할 때 정해진 `curDebate`값이 `handleDebate` 함수 내에서 변하지 않기 때문이었다. 그래서 setInterval로 1초마다 `isDebating: boolean`을 `setIsDebating((prevState) => !prevState)`로 바꿔줬고 usEffect로 토론 진행을 시켜줬다.

Ps. 이번 기회로 왜 React에서 사이드 이펙트를 useEffect로 관리해야 하는지를 깨달았다.

```ts
useEffect(() => {
  setCurDebate((prevState) => {
    if ((prevState.turn === 7 && prevState.time < 0) || !isStart) {
      return prevState;
    }

    if (prevState.turn < 7 && prevState.time < 2) {
      return {
        notice: debateProgress[prevState.turn + 1][0],
        turn: prevState.turn + 1,
        time: debateProgress[prevState.turn + 1][1],
      };
    } else {
      return {
        notice: prevState.notice,
        turn: prevState.turn,
        time: prevState.time - 1,
      };
    }
  });
}, [DEBATE_INFO.title, debateProgress, isDebating, isStart]); // dependency에 isDebating 필요
```

### 녹화 기능

다음으로는 녹화 기능이다. 오디오 스트림을 따로 합칠 필요도 없고 토론 종료 소켓 이벤트를 발동시킬 필요도 없어서 간단히 추가로 작성했다. 처음에는 토론을 시작할 때 `recorderRef`를 설정하고 녹화를 시작하게 했지만 20% 확률로 녹화가 진행되지 않는 문제가 있었다.

`recorderRef`의 설정과 녹화 시작이 너무 가까워서 그런가 하고 `recorderRef`의 설정을 방 입장 시 발생하는 useEffect에 넣어줬지만 여전히 문제가 해결되지 않았다.

그래서 코드를 더 꼼꼼히 살펴보자 사용자의 `stream`을 비동기로 받아서 `streamRef`에 저장하는데, `streamRef`를 바로 사용하는 게 문제라는 것을 깨달았다. 그래서 사용자의 `stream`을 비동기로 받는 then의 내부에 녹화 설정 로직을 넣어서 해결했다.

```ts
navigator.mediaDevices
  .getUserMedia({
    video: { facingMode: "user", width: 500, height: 500 },
    audio: { echoCancellation: true, noiseSuppression: true },
  })
  .then((stream) => {
    streamRef.current?.getTracks().forEach((track) => {
      track.stop();
    });
    streamRef.current = stream;
    if (videoRef.current) videoRef.current.srcObject = stream;
    //> 녹화 준비
    const mergedAudioRef = stream.getAudioTracks();
    const setRecorder = () => {
      //- 30fps로 캔버스 요소 녹화
      const canvasStream = canvasRef.current?.captureStream(30);
      ...
    }
    setRecorder();
})
```

### 화면 녹화 문제

<img width="1200" alt="녹화 영상 에러" src="https://user-images.githubusercontent.com/84524514/185723602-25d67ea6-7a3a-4551-b5f3-021b906ccfb9.png">

갑자기 녹화 영상이 재생되지 않는 문제가 발생했다. 처음에는 여전히 코드가 잘못된 것인가 생각했지만 이전에 잘 재생되었던 다른 영상도 재데로 작동하지 않는 것을 보고 코드가 아닌 다른 문제라고 생각했다.

생각해 보니 PR을 위해서 화면을 기록하던 도중에 녹화 영상이 재생되지 않아 그대로 다른 영상도 확인했었다. 화면 기록을 중지하고 다시 확인해 보니 이전에 잘 재생되었던 영상은 그대로 잘 재생됬고, 화면 기록과 동시에 녹화된 영상은 여전히 재생되지 않았다.

해당 내용은 사용자에게 알릴 필요가 있다고 생각해서 Q&A에 추가하고 중요 표시(❗️)를 해줬다.

### 영상 길이 표시

이전에 피드백이 들어왔던 부분이기도 하고 개인적으로도 신경 쓰이던 부분이 영상의 전체 시간이 나오지 않는다는 점이었다. 처음 보게 되면 영상 길이가 0초가 나오기도 하며 스트리밍이 되면서 계속 늘어나는 형태였고, 그래서 사용자가 헷갈릴 수 있었다.

이전에 Blob에 대해서 공부하면서 Blob의 메타 데이터에 대해서 알게 되었고, 추가로 알아보자 `MediaRecorder`는 메타 데이터에 영상의 길이(duration)을 포함하지 않는다는 것을 알게 되었다. 그래서 어떻게 추가할 수 있는지를 알아보았고 `fix-webm-duration`를 통해 추가했다.

_\*[fix-webm-duration npm 주소](https://www.npmjs.com/package/fix-webm-duration)_

```ts
recorderRef.current?.start(1000 / 30);
startTimeRef.current = Date.now();
```

```ts
recorderRef.current.onstop = () => {
  const duration = Date.now() - startTimeRef.current;
  const blob = new Blob(blobsRef.current, {
    type: "video/webm",
  });
  ysFixWebmDuration(blob, duration, { logger: false }).then((fixedBlob) => {
    blobRef.current = fixedBlob;
  });
};
```

- 기존 녹화 영상
  <img width="1200" alt="기존 녹화 영상" src="https://user-images.githubusercontent.com/84524514/185721920-ad7d95d5-0710-4cbf-9fd1-316e4f59be41.png">
- 개선 녹화 영상
  <img width="1200" alt="개선 녹화 영상" src="https://user-images.githubusercontent.com/84524514/185721892-d0dc3bcb-e2fc-403d-8817-be469f097e73.png">

## Ps. 문제 해결 능력이 오르고 있다!

확실히 문제 해결 능력이 오르고 있는 것을 느끼는 중이다. 예전에는 문제가 생겼을 때 해결에 집중하고 원인을 파악하지 못해서 헤맸다. 이제는 확실히 문제를 일으키지 않는 부분, 문제를 일으킬 여지가 있는 부분, 문제를 일으킬 것으로 의심되는 부분을 구분해서 하나하나 확인하면서 문제의 원인을 먼저 파악하고 원인에 맞는 해결책을 찾았다.

❗️문제 해결에서 가장 중요한 것은 문제의 원인 파악이다. 원인 파악이 안된 해결은 반의반의 반쪽짜리 해결일 뿐이다. 원인을 알아야 재발도 방지할 수 있다.
